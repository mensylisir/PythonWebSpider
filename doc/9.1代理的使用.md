# Python3 网络爬虫课程

## 代理的简单使用

我们在做爬虫的过程中经常遇到：爬虫运行的好好的，结果一会儿出现了错误，如 403 等。出现这个问题的原因是网站采取了一些反爬虫措施，服务器会检查 ip 在单位时间内的请求次数，如果超过了某个阈值，那么就会直接拒绝服务。怎么解决这个问题呢？就是这节课的代理的简单使用。

### 代理的设置

前面介绍了很多请求库，如 urllib、requests、selenium 等，下面介绍一下这些库怎么使用代理。

#### 获取代理

我们需要一个可用的代理，百度搜索“代理”，有很多免费的代理网站，比如西刺，当然，免费的代理一般都不好用，所以有条件的同学可以买付费代理。

#### urllib

```
from urllib.error import URLError
from urllib.request import ProxyHandler, build_opener

proxy = '127.0.0.1:7742'
proxy_handler = ProxyHandler({
    'http': 'http://' + proxy,
    'https': 'https://' + proxy
})
opener = build_opener(proxy_handler)
try:
    response = opener.open('http://httpbin.org/get')
    print(response.read().decode('utf-8'))
except URLError as e:
    print(e.reason)

```

#### requests

```
import requests
proxy = '127.0.0.1:7742'
proxies = {
    'http': 'http://' + proxy,
    'https': 'https://' + proxy
}
try:
    response = requests.get('http://httpbin.org/get', proxies=proxies)
    print(response.text)
except requests.exceptions.ConnectionError as e:
    print(e.args)
```

#### Selenium

```
from selenium import webdriver
proxy = '127.0.0.1:7742'

chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--proxy-server=http://' + proxy)
browser = webdriver.Chrome(chrome_options=chrome_options))
    browser.get('http://httpbin.org/get')
```
