# Python3网络爬虫课程
## BeautifulSoup
+ 简介
  - BeautifulSoup是Python的一个HTML或XML解析库
+ 安装
  ```
  pip install beautifulsoup4
  ```
+ 解析器
  - BeautifulSoup(markup, 'html.parser')
  - BeautifulSoup(markup, 'lxml')
  - BeautifulSoup(markup, 'xml')
  - BeautifulSoup(markup, 'html5lib')
+ 基本用法
```
from bs4 import BeautifulSoup

html = '''
    <html>
        <head>
            <title>Demo</title>
        </head>
        <body>
            <div>
                <ul>
                    <a href="link1.html">first item</a>
                    <li class="item1 item10"><a href="link1.html">first item</a>
                    <a href="link111.html">first11 item</a>
                    <span>8888888</span></li>
                    <li class="item2" name="item2"><a href="link2.html">second item</a>
                    <li class="item2"><a href="link3.html">third item</a></li>
                    <li class="item4"><a href="link4.html">fourth item</a></li>
                    <li class="item5"><a href="link5.html">fivth item</a></li>
                    <li class="item6"><a href="link6.html">sixth item</a></li>
                </ul>
            </div>
        </body>
    </html>
'''
soup = BeautifulSoup(html, 'lxml')
print(soup.prettify())
print(soup.title.string)
```
+ 选择元素
```
print(soup.title)
print(type(soup.title))
print(soup.title.string)
print(soup.head)
print(soup.a)
```
+ 提取信息
  - 获取名称
  ```
  soup.title.name
  ```
  - 获取属性
  ```
  soup.a.attrs['href']
  ```
  - 获取内容
  ```
  soup.a.string
  ```
  - 嵌套选择
  ```
  soup.head.title.string
  ```
  - 关联选择
    + 选择直接子节点
    ```
    soup.ul.contents
    soup.ul.children
    ```
    + 选择子孙节点
    ```
    soup.ul.descendants
    ```
    + 选择父节点
    ```
    soup.a.parent
    ```
    + 祖先节点
    ```
    soup.a.parents
    ```
    + 兄弟节点
    ```
    soup.a.next_sibling
    soup.a.next_siblings
    soup.li.previous_sibling
    soup.li.previous_siblings
    ```
    + 提取信息
    ```
    soup.a.string
    soup.a.next_sibling.string
    list(soup.a.parents)[0]
    list(soup.a.parents)[0].attrs['class']
    ```
  - 方法选择器
    + find_all()
      - name
      ```
      find_all(name, attrs, recursive, text, **kwargs)

      soup.find_all(name='li')

      for li in soup.find_all(name='li'):
          print(li.find_all(name='a'))

      for li in soup.find_all(name='li'):
          print(li.find_all(name='a'))
          for a in li.find_all(name='a'):
              print(a.string)
      ```
      - attrs
      ```
      soup.find_all(attrs={'class': 'item4'})
      soup.find_all(attrs={'class': 'item2'})
      soup.find_all(class_='item4')
      soup.find_all(id='li4')
      ```
      - text
      ```
      soup.find_all(text=re.compile('item'))
      soup.find_all(text=re.compile('.*?item.*?'))
      ```
    + find
    ```
    soup.find(name='li')
    ```
    + find_parents()
    + find_parent()
    + find_next_siblings()
    + find_next_sibling()
    + find_previous_siblings()
    + find_previous_sibling()
    + find_all_next()
    + find_next()
    + find_all_previous()
    + find_previous()
+ cssselector
```
soup.select('ul li a')

for ul in soup.select('ul'):
    for li in ul.select('li'):
        print(li.select('a'))

for ul in soup.select('ul'):
    for li in ul.select('li'):
        print(li['id'])
        print(li.attrs['id'])

for ul in soup.select('ul'):
    for li in ul.select('li'):
        for a in li.select('a'):
            print(a.string))
            print(a.get_text())
```
